{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "10OhbibAVvtr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "8hJUkVQOV8AM",
    "outputId": "3746b22f-9879-4cbc-c046-74dba81d6e02"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0             0.0                      0.0            0.0   \n",
       "1             0.0                      0.0            0.0   \n",
       "2             0.0                     -1.0            0.0   \n",
       "3             0.0                      0.0            0.0   \n",
       "4             0.0                      0.0            0.0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0             1.0                 0.000000   \n",
       "1                     0.0             2.0                64.000000   \n",
       "2                    -1.0             1.0                -1.000000   \n",
       "3                     0.0             2.0                 2.666667   \n",
       "4                     0.0            10.0               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('online_shoppers_intention.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FO_AdTjd9b9h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2\n",
      "1        2\n",
      "2        2\n",
      "3        2\n",
      "4        2\n",
      "        ..\n",
      "12325    1\n",
      "12326    7\n",
      "12327    7\n",
      "12328    7\n",
      "12329    7\n",
      "Name: Month, Length: 12316, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "dataset['Month'] = lb.fit_transform(dataset['Month'])\n",
    "dataset.dropna(inplace=True)\n",
    "print(dataset['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wYHc3-geWeUB"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kGgL0uxda47-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "X[:, 16] = le.fit_transform(X[:, 16])\n",
    "print(X[:,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b7gTvdvCBaC1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TEz-IzDpcOss"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [15])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "print(X[:,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YZmR-o6celDJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hlcdO39IhkMY"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential #used to initialize the NN\n",
    "from keras.layers import Dense  #used to build the hidden Layers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9852, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando as camadas de ann\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=8, activation='selu'))\n",
    "ann.add(tf.keras.layers.Dense(units=8, activation='selu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=8, activation='selu'))\n",
    "ann.add(tf.keras.layers.Dense(units=8, activation='selu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=8, activation='selu'))\n",
    "ann.add(tf.keras.layers.Dense(units=8, activation='selu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=8, activation='selu'))\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39813772, -0.0833674 ,  0.40969753, ...,  0.76835374,\n",
       "        -0.76362179,  1.80029653],\n",
       "       [ 2.51169372, -0.0833674 , -2.44082509, ..., -0.0605798 ,\n",
       "        -0.01554073, -0.55546405],\n",
       "       [-0.39813772, -0.0833674 ,  0.40969753, ...,  1.18282051,\n",
       "        -0.51426144, -0.55546405],\n",
       "       ...,\n",
       "       [-0.39813772, -0.0833674 ,  0.40969753, ..., -0.88951334,\n",
       "        -0.26490108, -0.55546405],\n",
       "       [ 2.51169372, -0.0833674 , -2.44082509, ..., -0.88951334,\n",
       "        -0.51426144,  1.80029653],\n",
       "       [-0.39813772, -0.0833674 ,  0.40969753, ...,  1.59728728,\n",
       "        -0.76362179,  1.80029653]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printando o x e o y de treino\n",
    "y_train\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "308/308 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.8449\n",
      "Epoch 2/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8734\n",
      "Epoch 3/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.3101 - accuracy: 0.8808\n",
      "Epoch 4/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2944 - accuracy: 0.8855\n",
      "Epoch 5/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.8897\n",
      "Epoch 6/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2751 - accuracy: 0.8925\n",
      "Epoch 7/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2700 - accuracy: 0.8947\n",
      "Epoch 8/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.8966\n",
      "Epoch 9/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2640 - accuracy: 0.8969\n",
      "Epoch 10/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.8973\n",
      "Epoch 11/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.8972\n",
      "Epoch 12/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2592 - accuracy: 0.8978\n",
      "Epoch 13/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2581 - accuracy: 0.8970\n",
      "Epoch 14/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2569 - accuracy: 0.8976\n",
      "Epoch 15/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.8968\n",
      "Epoch 16/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2552 - accuracy: 0.8972\n",
      "Epoch 17/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.8980\n",
      "Epoch 18/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.8985\n",
      "Epoch 19/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.8985\n",
      "Epoch 20/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2529 - accuracy: 0.8972\n",
      "Epoch 21/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.8982\n",
      "Epoch 22/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.8968\n",
      "Epoch 23/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2514 - accuracy: 0.8976\n",
      "Epoch 24/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.8987\n",
      "Epoch 25/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.8977\n",
      "Epoch 26/150\n",
      "308/308 [==============================] - 0s 991us/step - loss: 0.2492 - accuracy: 0.8998\n",
      "Epoch 27/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.8992\n",
      "Epoch 28/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.8971\n",
      "Epoch 29/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.8990\n",
      "Epoch 30/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.8976\n",
      "Epoch 31/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.8988\n",
      "Epoch 32/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.8970\n",
      "Epoch 33/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.8987\n",
      "Epoch 34/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.8986\n",
      "Epoch 35/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.8982\n",
      "Epoch 36/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.8992\n",
      "Epoch 37/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.8995\n",
      "Epoch 38/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.8988\n",
      "Epoch 39/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.8988\n",
      "Epoch 40/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.8996\n",
      "Epoch 41/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2440 - accuracy: 0.8995\n",
      "Epoch 42/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2433 - accuracy: 0.8997\n",
      "Epoch 43/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.9003\n",
      "Epoch 44/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.9009\n",
      "Epoch 45/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.8990\n",
      "Epoch 46/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.8991\n",
      "Epoch 47/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2421 - accuracy: 0.8991\n",
      "Epoch 48/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.9004\n",
      "Epoch 49/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.9005\n",
      "Epoch 50/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.8995\n",
      "Epoch 51/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.9000\n",
      "Epoch 52/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.9005\n",
      "Epoch 53/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.8995\n",
      "Epoch 54/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9001\n",
      "Epoch 55/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9003\n",
      "Epoch 56/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.8999\n",
      "Epoch 57/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.9004\n",
      "Epoch 58/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.8995\n",
      "Epoch 59/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.9007\n",
      "Epoch 60/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2380 - accuracy: 0.9003\n",
      "Epoch 61/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.8997\n",
      "Epoch 62/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2375 - accuracy: 0.9014\n",
      "Epoch 63/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9021\n",
      "Epoch 64/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.9005\n",
      "Epoch 65/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2371 - accuracy: 0.9022\n",
      "Epoch 66/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2365 - accuracy: 0.9007\n",
      "Epoch 67/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2365 - accuracy: 0.9005\n",
      "Epoch 68/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2366 - accuracy: 0.9012\n",
      "Epoch 69/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9007\n",
      "Epoch 70/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2357 - accuracy: 0.9006\n",
      "Epoch 71/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2349 - accuracy: 0.9027\n",
      "Epoch 72/150\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.2349 - accuracy: 0.9002\n",
      "Epoch 73/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.9015\n",
      "Epoch 74/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2347 - accuracy: 0.9012\n",
      "Epoch 75/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2343 - accuracy: 0.9016\n",
      "Epoch 76/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2339 - accuracy: 0.9024\n",
      "Epoch 77/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2344 - accuracy: 0.9026\n",
      "Epoch 78/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2344 - accuracy: 0.9012\n",
      "Epoch 79/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.9013\n",
      "Epoch 80/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.9008\n",
      "Epoch 81/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2339 - accuracy: 0.9016\n",
      "Epoch 82/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9022\n",
      "Epoch 83/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2327 - accuracy: 0.9012\n",
      "Epoch 84/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9014\n",
      "Epoch 85/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 0.9021\n",
      "Epoch 86/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.9019\n",
      "Epoch 87/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.9009\n",
      "Epoch 88/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.9012\n",
      "Epoch 89/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.9013\n",
      "Epoch 90/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2317 - accuracy: 0.9019\n",
      "Epoch 91/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2315 - accuracy: 0.9017\n",
      "Epoch 92/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9013\n",
      "Epoch 93/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.9014\n",
      "Epoch 94/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2315 - accuracy: 0.9016\n",
      "Epoch 95/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2312 - accuracy: 0.9024\n",
      "Epoch 96/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.9018\n",
      "Epoch 97/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.9017\n",
      "Epoch 98/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9019\n",
      "Epoch 99/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.9022\n",
      "Epoch 100/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.9005\n",
      "Epoch 101/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.9027\n",
      "Epoch 102/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.9015\n",
      "Epoch 103/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2301 - accuracy: 0.9021\n",
      "Epoch 104/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2297 - accuracy: 0.9028\n",
      "Epoch 105/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9028\n",
      "Epoch 106/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9014\n",
      "Epoch 107/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9016\n",
      "Epoch 108/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.9011\n",
      "Epoch 109/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.9010\n",
      "Epoch 110/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9028\n",
      "Epoch 111/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.9028\n",
      "Epoch 112/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2291 - accuracy: 0.9017\n",
      "Epoch 113/150\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9021\n",
      "Epoch 114/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9022\n",
      "Epoch 115/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9030\n",
      "Epoch 116/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.9016\n",
      "Epoch 117/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2283 - accuracy: 0.9018\n",
      "Epoch 118/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2284 - accuracy: 0.9026\n",
      "Epoch 119/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.9017\n",
      "Epoch 120/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.9024\n",
      "Epoch 121/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2282 - accuracy: 0.9018\n",
      "Epoch 122/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.9023\n",
      "Epoch 123/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.9023\n",
      "Epoch 124/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.9033\n",
      "Epoch 125/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.9009\n",
      "Epoch 126/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9021\n",
      "Epoch 127/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.9024\n",
      "Epoch 128/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9012\n",
      "Epoch 129/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2276 - accuracy: 0.9028\n",
      "Epoch 130/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.9033\n",
      "Epoch 131/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9027\n",
      "Epoch 132/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2266 - accuracy: 0.9036\n",
      "Epoch 133/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9033\n",
      "Epoch 134/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9026\n",
      "Epoch 135/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9031\n",
      "Epoch 136/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9035\n",
      "Epoch 137/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9021\n",
      "Epoch 138/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.9019\n",
      "Epoch 139/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9021\n",
      "Epoch 140/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2259 - accuracy: 0.9025\n",
      "Epoch 141/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9030\n",
      "Epoch 142/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9028\n",
      "Epoch 143/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2267 - accuracy: 0.9026\n",
      "Epoch 144/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9035\n",
      "Epoch 145/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9026\n",
      "Epoch 146/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9027\n",
      "Epoch 147/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9014\n",
      "Epoch 148/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 0.9024\n",
      "Epoch 149/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9014\n",
      "Epoch 150/150\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x275117cf880>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9852"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187188"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03476456],\n",
       "       [0.00033817],\n",
       "       [0.05433428],\n",
       "       ...,\n",
       "       [0.02239114],\n",
       "       [0.00245211],\n",
       "       [0.0698818 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probabilidade da pessoa comprar no site ou não\n",
    "#probabilidade de gerar receita ou não\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0.7 é o threshold\n",
    "y_pred = (y_pred > 0.50)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1998   90]\n",
      " [ 169  207]]\n"
     ]
    }
   ],
   "source": [
    "#acertou 1985 e 232\n",
    "#errou 103 e 144\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "deep_learning_project.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
